{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data load from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# 第一個檔案是訓練資料集 (6 種分類)。\n",
    "!gdown --id '1QGB_C4DvhotmvFIH3BM3PBHTYG_clGQl' --output /content/train_6class.zip\n",
    "# 第二個檔案是測試資料集 (10 種分類)。\n",
    "!gdown --id '19ar3WmD3NDAmldXGyH06a6gf58tbQ5eA' --output /content/test_10class.zip\n",
    "\n",
    "with zipfile.ZipFile('/content/train_6class.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/train_6class')\n",
    "\n",
    "with zipfile.ZipFile('/content/test_10class.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/test_10class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_data = ImageFolder('/content/train_6class', transform = preprocess)\n",
    "\n",
    "#設定Validation data比例\n",
    "valid_size = 0.2\n",
    "\n",
    "# 將索引列表隨機打亂\n",
    "num_train = len(train_data)\n",
    "print(num_train)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "# 根據驗證集比例計算分割點 (索引切分位置)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "print(split)\n",
    "\n",
    "# 將打亂的索引分割為訓練集與驗證集，創建訓練與驗證數據的sampler\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_idx)\n",
    "print(train_sampler)\n",
    "print(valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 定義繪製損失曲線的函數\n",
    "def plotfigure(train_loss,valid_loss):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "    plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "    # find position of lowest validation loss\n",
    "    # minposs = valid_loss.index(min(valid_loss))+1\n",
    "    # plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    # plt.ylim(0, 2) # consistent scale\n",
    "    plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=num_class)\n",
    "model_nopre_6class = EfficientNet.from_name('efficientnet-b1', num_classes=6)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion_nopre_6class = nn.CrossEntropyLoss()\n",
    "optimizer_nopre_6class = optim.Adam(model_nopre_6class.parameters(), lr=0.005)\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#直接load之前已經訓練過的6類model\n",
    "model_nopre_6class = EfficientNet.from_name('efficientnet-b1', num_classes=6)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_nopre_6class.load_state_dict(torch.load('/content/save.pt'))\n",
    "model_nopre_6class.to(device)\n",
    "model_nopre_6class.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = [] # 用於存儲每次訓練批次的損失\n",
    "valid_losses = [] # 用於存儲每次驗證批次的損失\n",
    "avg_train_losses = [] # 用於存儲每個 epoch 的平均訓練損失\n",
    "avg_valid_losses = [] # 用於存儲每個 epoch 的平均驗證損失\n",
    "\n",
    "# 初始化每個類別的置信度閾值為 1\n",
    "threshold = {0 : 1, 1 : 1, 2 : 1, 3 : 1, 4 : 1, 5 : 1}\n",
    "\n",
    "model_nopre_6class.to(device)\n",
    "for epoch in range(epoch):\n",
    "  model_nopre_6class.train()\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer_nopre_6class.zero_grad()\n",
    "    outputs = model_nopre_6class(images)\n",
    "    loss = criterion_nopre_6class(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer_nopre_6class.step()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "  model_nopre_6class.eval()\n",
    "  validation_loss = 0.0\n",
    "  correct_predictions = 0\n",
    "  total_samples = 0\n",
    "  with torch.no_grad():\n",
    "    for i,(images, labels) in enumerate(valid_loader):\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model_nopre_6class(images)\n",
    "      val_loss = criterion_nopre_6class(outputs, labels)\n",
    "      valid_losses.append(val_loss.item())\n",
    "      \n",
    "      # 計算每個類別的置信度閾值\n",
    "      probabilities = torch.softmax(outputs, dim=1)\n",
    "      predicted = torch.argmax(probabilities, dim=1)\n",
    "      for i in range(len(predicted)):\n",
    "        if predicted[i] == labels[i]:\n",
    "          correct_predictions += 1\n",
    "          # 更新該類別的置信度閾值\n",
    "          if probabilities[i][predicted.cpu().numpy()[i]].cpu().numpy() < threshold[predicted.cpu().numpy()[i]]:\n",
    "            threshold[predicted.cpu().numpy()[i]] = probabilities[i][predicted.cpu().numpy()[i]].cpu().numpy()\n",
    "      #val acc\n",
    "      _, predicted = torch.max(outputs,1)\n",
    "      correct_predictions += (predicted == labels).sum().item()\n",
    "      total_samples += labels.size(0)\n",
    "      \n",
    "  train_loss = np.average(train_losses)\n",
    "  valid_loss = np.average(valid_losses)\n",
    "  avg_train_losses.append(train_loss)\n",
    "  avg_valid_losses.append(valid_loss)\n",
    "  print(\"Epoch {} - Train loss: {:.4f}, Validation loss:{:.4f}, Validation accuracy:{:.4f}\".format(epoch+1, train_loss, valid_loss,(correct_predictions/total_samples)))\n",
    "  train_loss=[]\n",
    "  valid_loss=[]\n",
    "for i in range(len(threshold)):\n",
    "  print(f'Class {i} threshold: {threshold[i]}')\n",
    "plotfigure(avg_train_losses,avg_valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model_nopre_6class.state_dict(), '/content/save.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 用和訓練資料集同樣的六類測試data測試模型訓練分類效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!gdown --id '1akuOLZjxZB813WFVBd6y-BQdqh9lz7Me' --output /content/test_6class.zip\n",
    "\n",
    "with zipfile.ZipFile('/content/test_6class.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/test_6class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_loader_6c = DataLoader(ImageFolder('/content/test_6class',transform = preprocess), batch_size=32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_nopre_6class.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader_6c):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_nopre_6class(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        max_prob, predicted = torch.max(probabilities,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        # print(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        # print(true_labels)\n",
    "acc = correct / total\n",
    "print(\"Test Accuracy: {:.4f}\".format(acc))\n",
    "#confusion_matrix\n",
    "print(metrics.confusion_matrix(true_labels, predictions))\n",
    "print(metrics.classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用10類的test data作test並分出other類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_nopre_6class.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "true_labels = []\n",
    "other_samples_10class = [] # 儲存低置信度的樣本特徵\n",
    "other_labels_10class = [] # 儲存低置信度樣本的真實標籤\n",
    "avg_pooling = nn.AdaptiveAvgPool2d(1) #全局平均池化以獲取壓縮的特徵表示\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_nopre_6class(images)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        max_prob, predicted = torch.max(probabilities,1)\n",
    "        total += labels.size(0)\n",
    "        # correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 將低於置信度閾值的樣本標記為類別 6（未知類別）\n",
    "        for j in range(len(predicted)):\n",
    "          # if predicted[j] != labels[j]:\n",
    "          if max_prob[j].cpu().numpy() < threshold_2[predicted.cpu().numpy()[j]]: \n",
    "            predicted[j] = 6\n",
    "\n",
    "        # 提取低置信度樣本的特徵和標籤\n",
    "        for j in range(len(predicted)):\n",
    "          if predicted[j] == 6:\n",
    "            image_batch = images[j].unsqueeze(0)\n",
    "            image_batch = image_batch.to(device)\n",
    "            features = model_nopre_6class.extract_features(image_batch)\n",
    "            fea = avg_pooling(features)\n",
    "            other_samples_10class.append(fea.cpu().numpy())  # 樣本加到列表\n",
    "            other_labels_10class.append(labels[j].cpu().numpy())  # label加到列表\n",
    "            # if labels[j] == 7 or labels[j] == 8 or labels[j] == 9:\n",
    "            #   correct += 1\n",
    "            \n",
    "        # 將真實標籤 7、8、9 轉換為類別 6（因為6為others類別，將原本就不再訓練資料集的7,8,9類設成others類）\n",
    "        for j in range(len(labels)):\n",
    "          if(labels[j] == 7 or labels[j] == 8 or labels[j] == 9):\n",
    "            labels[j] = 6\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        # print(predictions)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        # print(true_labels)\n",
    "\n",
    "acc = correct / total\n",
    "print(\"Test Accuracy: {:.4f}\".format(acc))\n",
    "#confusion_matrix\n",
    "print(metrics.confusion_matrix(true_labels, predictions))\n",
    "print(metrics.classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將被分到others類別的樣本進行重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(len(other_samples_10class))\n",
    "print(len(other_labels_10class))\n",
    "other_samples_10class = np.array(other_samples_10class)\n",
    "# 去掉平均池化後的多餘維度（squeeze 第 1 維）\n",
    "other_samples_10class = other_samples_10class.squeeze(1)\n",
    "other_labels_10class = np.array(other_labels_10class)\n",
    "\n",
    "print(other_samples_10class.shape)\n",
    "print(other_labels_10class.shape)\n",
    "n_samples, channels, width, height = other_samples_10class.shape\n",
    "print(n_samples, channels, width, height)\n",
    "\n",
    "# 將樣本展平處理，每個樣本展平成一維向量\n",
    "other_samples_10class_flat = other_samples_10class.reshape(n_samples, height * width * channels)\n",
    "print(other_samples_10class_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#因為第9類是normal類別，將不是normal類別其他標籤都轉為1，是normal的標籤轉為0\n",
    "for i in range(len(other_labels_10class)):\n",
    "  if other_labels_10class[i] != 9:\n",
    "    other_labels_10class[i] = 1\n",
    "  else:\n",
    "    other_labels_10class[i] = 0\n",
    "print(other_labels_10class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mahalanobis distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用normal data的訓練資料取得馬氏距離所需的平均值、斜方差逆矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "!gdown --id \"1u3jlb_D5VrlIeK0wBC2D3qTMWLiJPK8B\" --output /content/normalonly.zip\n",
    "\n",
    "with zipfile.ZipFile('/content/normalonly.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/normalonly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "normalonly_loader = DataLoader(ImageFolder('/content/normalonly',transform = preprocess), batch_size=32, shuffle = False)\n",
    "model_nopre_6class.eval()\n",
    "normalonlyarr=[]\n",
    "model_nopre_6class.to(device)\n",
    "with torch.no_grad():\n",
    "    for i,(images, labels) in enumerate(normalonly_loader):\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      for j in range(len(images)):\n",
    "        image_batch = images[j].unsqueeze(0)\n",
    "        features = model_nopre_6class.extract_features(image_batch)\n",
    "        fea = avg_pooling(features)\n",
    "        normalonlyarr.append(fea.cpu().numpy())  # 樣本加到列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重塑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(len(normalonlyarr))\n",
    "normalonlyarr = np.array(normalonlyarr)\n",
    "normalonlyarr = normalonlyarr.squeeze(1)\n",
    "print(normalonlyarr.shape)\n",
    "n_samples, channels, width, height = normalonlyarr.shape\n",
    "print(n_samples, channels, width, height)\n",
    "normalonlyarr_flat = normalonlyarr.reshape(n_samples, height * width * channels)\n",
    "print(normalonlyarr_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用normal類的訓練資料來獲得馬氏距離所需的平均值、斜方差逆矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#用normal類的訓練資料來獲得馬氏距離所需的平均值、斜方差逆矩陣\n",
    "mean = np.mean(normalonlyarr_flat, axis=0)\n",
    "cov = np.cov(normalonlyarr_flat.T)\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "#用normal類的訓練資料的第一個樣本作馬氏距離測試\n",
    "diff = normalonlyarr_flat[0] - mean\n",
    "mahalanobis_distance = np.dot(diff.T, cov_inv)\n",
    "mahalanobis_distance = np.dot(mahalanobis_distance, diff)\n",
    "mahalanobis_distance = np.sqrt(mahalanobis_distance)\n",
    "print(mahalanobis_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#用全部normal類的訓練資料作馬氏距離測試並存到all_val內\n",
    "all_val=[]\n",
    "for i in range(len(normalonlyarr_flat)):\n",
    "  diff = normalonlyarr_flat[i] - mean\n",
    "  mahalanobis_distance = np.dot(diff.T, cov_inv)\n",
    "  mahalanobis_distance = np.dot(mahalanobis_distance, diff)\n",
    "  mahalanobis_distance = np.sqrt(mahalanobis_distance)\n",
    "  all_val.append(mahalanobis_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用全部normal類的訓練資料作馬氏距離的平均作threshold作OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#計算馬氏距離非 NaN 平均值\n",
    "mean_value = np.nanmean(all_val)\n",
    "print(mean_value)\n",
    "for i in range(len(all_val)):\n",
    "  if np.isnan(all_val[i]):\n",
    "    all_val[i] = mean_value\n",
    "print(all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#把分到others類別的樣本作馬氏距離OOD作分類\n",
    "other_val=[] # 保存每個樣本的 Mahalanobis 距離\n",
    "other_val_label=[] # 保存每個樣本的預測標籤\n",
    "# 計算其他樣本的 Mahalanobis 距離\n",
    "for i in range(len(other_samples_10class_flat)):\n",
    "  diff = other_samples_10class_flat[i] - mean\n",
    "  mahalanobis_distance = np.dot(diff.T, cov_inv)\n",
    "  mahalanobis_distance = np.dot(mahalanobis_distance, diff)\n",
    "  mahalanobis_distance = np.sqrt(mahalanobis_distance)\n",
    "  other_val.append(mahalanobis_distance)\n",
    "print(other_val)\n",
    "# 處理 NaN 值，替換 NaN 距離為平均值\n",
    "mean_value = np.nanmean(other_val)\n",
    "print(mean_value)\n",
    "for i in range(len(other_val)):\n",
    "  if np.isnan(other_val[i]):\n",
    "    other_val[i] = mean_value\n",
    "print(other_val)\n",
    "\n",
    "# 判定樣本是否為OOD，如果距離大於 all_val 中的最大值\n",
    "for i in range(len(other_val)):\n",
    "  if other_val[i] > max(all_val):\n",
    "    other_val_label.append(1)\n",
    "  else:\n",
    "    other_val_label.append(0)\n",
    "print(metrics.confusion_matrix(other_labels_10class, other_val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(other_labels_10class)\n",
    "print(other_val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用全部normal類的訓練資料作馬氏距離的中位數作threshold作OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#用中位數測試\n",
    "sorted_all_val = sorted(all_val)\n",
    "print(all_val)\n",
    "print(sorted_all_val)\n",
    "med = np.median(sorted_all_val)\n",
    "print(med)\n",
    "med_label = []\n",
    "for i in range(len(other_val)):\n",
    "  if other_val[i] > med:\n",
    "    med_label.append(1)\n",
    "  else:\n",
    "    med_label.append(0)\n",
    "print(metrics.confusion_matrix(other_labels_10class, med_label))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
